{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../data/train.csv', index_col=False)\n",
    "x_test = pd.read_csv('../data/test.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train.pop('label')\n",
    "y_test = x_test.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(53, 53)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 2, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 53)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Neural Network ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
    "from keras import metrics\n",
    "# !pip install keras-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras_metrics as km #when compiling\n",
    "import keras\n",
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 - 1s - loss: 2.1313 - accuracy: 0.5519 - f1_m: 0.0694 - precision_m: 0.6073 - recall_m: 0.0433 - 1s/epoch - 25ms/step\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.8387 - accuracy: 0.7238 - f1_m: 0.6898 - precision_m: 0.7009 - recall_m: 0.7238 - 219ms/epoch - 5ms/step\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.4547 - accuracy: 0.8125 - f1_m: 0.7074 - precision_m: 0.5602 - recall_m: 0.9609 - 189ms/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.3561 - accuracy: 0.8415 - f1_m: 0.7086 - precision_m: 0.5519 - recall_m: 0.9899 - 183ms/epoch - 4ms/step\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.3018 - accuracy: 0.8584 - f1_m: 0.7101 - precision_m: 0.5519 - recall_m: 0.9957 - 203ms/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.2672 - accuracy: 0.8722 - f1_m: 0.7111 - precision_m: 0.5524 - recall_m: 0.9981 - 177ms/epoch - 4ms/step\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.2437 - accuracy: 0.8796 - f1_m: 0.7098 - precision_m: 0.5506 - recall_m: 0.9986 - 215ms/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.2264 - accuracy: 0.8896 - f1_m: 0.7100 - precision_m: 0.5508 - recall_m: 0.9989 - 208ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.2140 - accuracy: 0.8985 - f1_m: 0.7101 - precision_m: 0.5508 - recall_m: 0.9992 - 141ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.2051 - accuracy: 0.9049 - f1_m: 0.7103 - precision_m: 0.5511 - recall_m: 0.9991 - 169ms/epoch - 4ms/step\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.1983 - accuracy: 0.9101 - f1_m: 0.7109 - precision_m: 0.5518 - recall_m: 0.9993 - 201ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.1927 - accuracy: 0.9135 - f1_m: 0.7102 - precision_m: 0.5509 - recall_m: 0.9995 - 209ms/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.1871 - accuracy: 0.9185 - f1_m: 0.7102 - precision_m: 0.5508 - recall_m: 0.9995 - 164ms/epoch - 4ms/step\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.1823 - accuracy: 0.9218 - f1_m: 0.7102 - precision_m: 0.5508 - recall_m: 0.9996 - 191ms/epoch - 5ms/step\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.1776 - accuracy: 0.9266 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 0.9998 - 210ms/epoch - 5ms/step\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.1734 - accuracy: 0.9297 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 0.9998 - 181ms/epoch - 4ms/step\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.1692 - accuracy: 0.9323 - f1_m: 0.7096 - precision_m: 0.5502 - recall_m: 0.9995 - 200ms/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.1655 - accuracy: 0.9356 - f1_m: 0.7096 - precision_m: 0.5501 - recall_m: 0.9998 - 240ms/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.1624 - accuracy: 0.9366 - f1_m: 0.7093 - precision_m: 0.5497 - recall_m: 0.9999 - 286ms/epoch - 7ms/step\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.1593 - accuracy: 0.9392 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 0.9998 - 145ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.1560 - accuracy: 0.9414 - f1_m: 0.7095 - precision_m: 0.5499 - recall_m: 0.9997 - 136ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.1537 - accuracy: 0.9424 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 0.9997 - 142ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.1512 - accuracy: 0.9438 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 0.9999 - 141ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.1486 - accuracy: 0.9454 - f1_m: 0.7102 - precision_m: 0.5508 - recall_m: 0.9998 - 169ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.1463 - accuracy: 0.9462 - f1_m: 0.7109 - precision_m: 0.5516 - recall_m: 0.9999 - 176ms/epoch - 4ms/step\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.1444 - accuracy: 0.9473 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 0.9999 - 233ms/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.1425 - accuracy: 0.9479 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 0.9999 - 215ms/epoch - 5ms/step\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.1410 - accuracy: 0.9477 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 0.9999 - 219ms/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.1390 - accuracy: 0.9492 - f1_m: 0.7095 - precision_m: 0.5498 - recall_m: 0.9999 - 161ms/epoch - 4ms/step\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.1376 - accuracy: 0.9489 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 0.9999 - 156ms/epoch - 4ms/step\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.1354 - accuracy: 0.9503 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 0.9999 - 143ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.1339 - accuracy: 0.9499 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 147ms/epoch - 4ms/step\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.1331 - accuracy: 0.9511 - f1_m: 0.7095 - precision_m: 0.5499 - recall_m: 0.9999 - 167ms/epoch - 4ms/step\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.1314 - accuracy: 0.9513 - f1_m: 0.7095 - precision_m: 0.5500 - recall_m: 1.0000 - 147ms/epoch - 3ms/step\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.1301 - accuracy: 0.9521 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 1.0000 - 145ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.1294 - accuracy: 0.9518 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 0.9999 - 164ms/epoch - 4ms/step\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.1279 - accuracy: 0.9530 - f1_m: 0.7101 - precision_m: 0.5505 - recall_m: 0.9999 - 138ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.1270 - accuracy: 0.9526 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 155ms/epoch - 4ms/step\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.1262 - accuracy: 0.9528 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 0.9999 - 150ms/epoch - 4ms/step\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.1251 - accuracy: 0.9538 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.1247 - accuracy: 0.9529 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 0.9999 - 146ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.1234 - accuracy: 0.9537 - f1_m: 0.7109 - precision_m: 0.5516 - recall_m: 1.0000 - 150ms/epoch - 4ms/step\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.1226 - accuracy: 0.9533 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 0.9998 - 152ms/epoch - 4ms/step\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.1220 - accuracy: 0.9534 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 0.9998 - 158ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.1208 - accuracy: 0.9543 - f1_m: 0.7097 - precision_m: 0.5502 - recall_m: 1.0000 - 146ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.1196 - accuracy: 0.9552 - f1_m: 0.7108 - precision_m: 0.5514 - recall_m: 0.9999 - 150ms/epoch - 4ms/step\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.1187 - accuracy: 0.9546 - f1_m: 0.7093 - precision_m: 0.5497 - recall_m: 1.0000 - 154ms/epoch - 4ms/step\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.1183 - accuracy: 0.9551 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 147ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.1176 - accuracy: 0.9549 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 0.9999 - 144ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.1167 - accuracy: 0.9554 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.1159 - accuracy: 0.9559 - f1_m: 0.7110 - precision_m: 0.5517 - recall_m: 0.9999 - 136ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.1161 - accuracy: 0.9554 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 0.9999 - 142ms/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.1159 - accuracy: 0.9550 - f1_m: 0.7106 - precision_m: 0.5512 - recall_m: 1.0000 - 145ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.1142 - accuracy: 0.9560 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 147ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.1142 - accuracy: 0.9555 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.1130 - accuracy: 0.9559 - f1_m: 0.7101 - precision_m: 0.5505 - recall_m: 1.0000 - 147ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.1122 - accuracy: 0.9566 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.1117 - accuracy: 0.9564 - f1_m: 0.7097 - precision_m: 0.5502 - recall_m: 1.0000 - 148ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.1116 - accuracy: 0.9560 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 0.9999 - 141ms/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.1106 - accuracy: 0.9566 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 0.9999 - 135ms/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.1101 - accuracy: 0.9566 - f1_m: 0.7104 - precision_m: 0.5510 - recall_m: 1.0000 - 137ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.1100 - accuracy: 0.9560 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 158ms/epoch - 4ms/step\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.1087 - accuracy: 0.9570 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 153ms/epoch - 4ms/step\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.1086 - accuracy: 0.9566 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 0.9999 - 157ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.1086 - accuracy: 0.9565 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 157ms/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.1079 - accuracy: 0.9569 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 159ms/epoch - 4ms/step\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.1075 - accuracy: 0.9570 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 151ms/epoch - 4ms/step\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.1066 - accuracy: 0.9573 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 150ms/epoch - 4ms/step\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.1061 - accuracy: 0.9577 - f1_m: 0.7104 - precision_m: 0.5510 - recall_m: 1.0000 - 156ms/epoch - 4ms/step\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.1052 - accuracy: 0.9580 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 0.9999 - 155ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.1055 - accuracy: 0.9577 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 1.0000 - 148ms/epoch - 4ms/step\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.1047 - accuracy: 0.9580 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 146ms/epoch - 3ms/step\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.1052 - accuracy: 0.9572 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 144ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.1040 - accuracy: 0.9581 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 145ms/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.1041 - accuracy: 0.9581 - f1_m: 0.7106 - precision_m: 0.5512 - recall_m: 0.9999 - 151ms/epoch - 4ms/step\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.1048 - accuracy: 0.9585 - f1_m: 0.7104 - precision_m: 0.5509 - recall_m: 1.0000 - 139ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.1037 - accuracy: 0.9579 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.1032 - accuracy: 0.9578 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 135ms/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.1037 - accuracy: 0.9582 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 138ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.1024 - accuracy: 0.9582 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.1024 - accuracy: 0.9586 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 141ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.1027 - accuracy: 0.9584 - f1_m: 0.7105 - precision_m: 0.5510 - recall_m: 1.0000 - 156ms/epoch - 4ms/step\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.1018 - accuracy: 0.9585 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.1016 - accuracy: 0.9587 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 138ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.1019 - accuracy: 0.9585 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.1019 - accuracy: 0.9584 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 1.0000 - 146ms/epoch - 3ms/step\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.1010 - accuracy: 0.9590 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 135ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.1011 - accuracy: 0.9591 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 138ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.1021 - accuracy: 0.9587 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.1021 - accuracy: 0.9581 - f1_m: 0.7105 - precision_m: 0.5510 - recall_m: 1.0000 - 139ms/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.1008 - accuracy: 0.9592 - f1_m: 0.7103 - precision_m: 0.5509 - recall_m: 1.0000 - 139ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.1003 - accuracy: 0.9589 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 138ms/epoch - 3ms/step\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.1002 - accuracy: 0.9589 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.1001 - accuracy: 0.9588 - f1_m: 0.7108 - precision_m: 0.5515 - recall_m: 1.0000 - 141ms/epoch - 3ms/step\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0999 - accuracy: 0.9591 - f1_m: 0.7107 - precision_m: 0.5514 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0998 - accuracy: 0.9591 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 153ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0996 - accuracy: 0.9594 - f1_m: 0.7104 - precision_m: 0.5509 - recall_m: 1.0000 - 138ms/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0997 - accuracy: 0.9592 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 137ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0999 - accuracy: 0.9591 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 137ms/epoch - 3ms/step\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.1000 - accuracy: 0.9593 - f1_m: 0.7113 - precision_m: 0.5522 - recall_m: 1.0000 - 134ms/epoch - 3ms/step\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0995 - accuracy: 0.9595 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 157ms/epoch - 4ms/step\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0990 - accuracy: 0.9597 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 152ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0991 - accuracy: 0.9595 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 151ms/epoch - 4ms/step\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0993 - accuracy: 0.9596 - f1_m: 0.7108 - precision_m: 0.5515 - recall_m: 1.0000 - 148ms/epoch - 4ms/step\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0991 - accuracy: 0.9592 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 224ms/epoch - 5ms/step\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0992 - accuracy: 0.9596 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 154ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0988 - accuracy: 0.9600 - f1_m: 0.7109 - precision_m: 0.5516 - recall_m: 1.0000 - 135ms/epoch - 3ms/step\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0981 - accuracy: 0.9600 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0982 - accuracy: 0.9597 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 136ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0987 - accuracy: 0.9589 - f1_m: 0.7104 - precision_m: 0.5509 - recall_m: 1.0000 - 139ms/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0990 - accuracy: 0.9593 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 146ms/epoch - 3ms/step\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0983 - accuracy: 0.9599 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 154ms/epoch - 4ms/step\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0981 - accuracy: 0.9597 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 147ms/epoch - 4ms/step\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0984 - accuracy: 0.9595 - f1_m: 0.7101 - precision_m: 0.5505 - recall_m: 1.0000 - 176ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0977 - accuracy: 0.9602 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 147ms/epoch - 3ms/step\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9601 - f1_m: 0.7095 - precision_m: 0.5499 - recall_m: 1.0000 - 156ms/epoch - 4ms/step\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9601 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 193ms/epoch - 5ms/step\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0972 - accuracy: 0.9604 - f1_m: 0.7094 - precision_m: 0.5498 - recall_m: 1.0000 - 165ms/epoch - 4ms/step\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0984 - accuracy: 0.9596 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 191ms/epoch - 5ms/step\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0976 - accuracy: 0.9602 - f1_m: 0.7111 - precision_m: 0.5519 - recall_m: 1.0000 - 186ms/epoch - 4ms/step\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0977 - accuracy: 0.9601 - f1_m: 0.7092 - precision_m: 0.5496 - recall_m: 1.0000 - 182ms/epoch - 4ms/step\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0968 - accuracy: 0.9605 - f1_m: 0.7104 - precision_m: 0.5510 - recall_m: 1.0000 - 213ms/epoch - 5ms/step\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0968 - accuracy: 0.9602 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 256ms/epoch - 6ms/step\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9597 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 129ms/epoch - 3ms/step\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0965 - accuracy: 0.9608 - f1_m: 0.7103 - precision_m: 0.5509 - recall_m: 1.0000 - 182ms/epoch - 4ms/step\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0967 - accuracy: 0.9602 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 135ms/epoch - 3ms/step\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0967 - accuracy: 0.9600 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 172ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0965 - accuracy: 0.9605 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 178ms/epoch - 4ms/step\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0966 - accuracy: 0.9608 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 166ms/epoch - 4ms/step\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0968 - accuracy: 0.9601 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 176ms/epoch - 4ms/step\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0964 - accuracy: 0.9602 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0967 - accuracy: 0.9602 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 157ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0965 - accuracy: 0.9606 - f1_m: 0.7094 - precision_m: 0.5498 - recall_m: 1.0000 - 137ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0962 - accuracy: 0.9605 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0954 - accuracy: 0.9605 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 130ms/epoch - 3ms/step\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0956 - accuracy: 0.9611 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 164ms/epoch - 4ms/step\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0957 - accuracy: 0.9606 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 206ms/epoch - 5ms/step\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0956 - accuracy: 0.9604 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 204ms/epoch - 5ms/step\n",
      "Epoch 139/200\n",
      "42/42 - 0s - loss: 0.0953 - accuracy: 0.9608 - f1_m: 0.7107 - precision_m: 0.5514 - recall_m: 1.0000 - 208ms/epoch - 5ms/step\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0955 - accuracy: 0.9610 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 174ms/epoch - 4ms/step\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0953 - accuracy: 0.9608 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 134ms/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0952 - accuracy: 0.9610 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 144ms/epoch - 3ms/step\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0950 - accuracy: 0.9613 - f1_m: 0.7105 - precision_m: 0.5511 - recall_m: 1.0000 - 152ms/epoch - 4ms/step\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0956 - accuracy: 0.9605 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0948 - accuracy: 0.9611 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0949 - accuracy: 0.9613 - f1_m: 0.7105 - precision_m: 0.5510 - recall_m: 1.0000 - 131ms/epoch - 3ms/step\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0948 - accuracy: 0.9613 - f1_m: 0.7093 - precision_m: 0.5496 - recall_m: 1.0000 - 165ms/epoch - 4ms/step\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0954 - accuracy: 0.9607 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 1.0000 - 143ms/epoch - 3ms/step\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0956 - accuracy: 0.9613 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 156ms/epoch - 4ms/step\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0947 - accuracy: 0.9614 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 149ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0950 - accuracy: 0.9610 - f1_m: 0.7098 - precision_m: 0.5502 - recall_m: 1.0000 - 160ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0946 - accuracy: 0.9613 - f1_m: 0.7092 - precision_m: 0.5495 - recall_m: 1.0000 - 150ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0943 - accuracy: 0.9616 - f1_m: 0.7106 - precision_m: 0.5512 - recall_m: 1.0000 - 140ms/epoch - 3ms/step\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0951 - accuracy: 0.9610 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 147ms/epoch - 4ms/step\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0950 - accuracy: 0.9611 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 174ms/epoch - 4ms/step\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0943 - accuracy: 0.9616 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 209ms/epoch - 5ms/step\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0942 - accuracy: 0.9616 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 209ms/epoch - 5ms/step\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0940 - accuracy: 0.9612 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 197ms/epoch - 5ms/step\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0940 - accuracy: 0.9612 - f1_m: 0.7098 - precision_m: 0.5503 - recall_m: 1.0000 - 193ms/epoch - 5ms/step\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0943 - accuracy: 0.9614 - f1_m: 0.7106 - precision_m: 0.5513 - recall_m: 1.0000 - 190ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0944 - accuracy: 0.9612 - f1_m: 0.7107 - precision_m: 0.5514 - recall_m: 1.0000 - 128ms/epoch - 3ms/step\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0937 - accuracy: 0.9616 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 168ms/epoch - 4ms/step\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0944 - accuracy: 0.9618 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 160ms/epoch - 4ms/step\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0936 - accuracy: 0.9616 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 150ms/epoch - 4ms/step\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0939 - accuracy: 0.9620 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 294ms/epoch - 7ms/step\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0938 - accuracy: 0.9616 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 248ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0941 - accuracy: 0.9615 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 191ms/epoch - 5ms/step\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0941 - accuracy: 0.9621 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 158ms/epoch - 4ms/step\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0935 - accuracy: 0.9615 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 221ms/epoch - 5ms/step\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0938 - accuracy: 0.9620 - f1_m: 0.7102 - precision_m: 0.5507 - recall_m: 1.0000 - 185ms/epoch - 4ms/step\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0952 - accuracy: 0.9605 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 193ms/epoch - 5ms/step\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0935 - accuracy: 0.9618 - f1_m: 0.7108 - precision_m: 0.5515 - recall_m: 1.0000 - 171ms/epoch - 4ms/step\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0934 - accuracy: 0.9620 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0933 - accuracy: 0.9620 - f1_m: 0.7100 - precision_m: 0.5504 - recall_m: 1.0000 - 182ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0938 - accuracy: 0.9615 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 188ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0935 - accuracy: 0.9620 - f1_m: 0.7094 - precision_m: 0.5498 - recall_m: 1.0000 - 204ms/epoch - 5ms/step\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0934 - accuracy: 0.9622 - f1_m: 0.7108 - precision_m: 0.5514 - recall_m: 1.0000 - 208ms/epoch - 5ms/step\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0928 - accuracy: 0.9620 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 131ms/epoch - 3ms/step\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0928 - accuracy: 0.9619 - f1_m: 0.7100 - precision_m: 0.5505 - recall_m: 1.0000 - 127ms/epoch - 3ms/step\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0932 - accuracy: 0.9620 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 133ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0930 - accuracy: 0.9618 - f1_m: 0.7104 - precision_m: 0.5509 - recall_m: 1.0000 - 149ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0931 - accuracy: 0.9617 - f1_m: 0.7101 - precision_m: 0.5507 - recall_m: 1.0000 - 194ms/epoch - 5ms/step\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0930 - accuracy: 0.9620 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 159ms/epoch - 4ms/step\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0925 - accuracy: 0.9623 - f1_m: 0.7104 - precision_m: 0.5510 - recall_m: 1.0000 - 154ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0925 - accuracy: 0.9622 - f1_m: 0.7099 - precision_m: 0.5503 - recall_m: 1.0000 - 146ms/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0930 - accuracy: 0.9622 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 132ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0923 - accuracy: 0.9623 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 142ms/epoch - 3ms/step\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0925 - accuracy: 0.9624 - f1_m: 0.7106 - precision_m: 0.5512 - recall_m: 1.0000 - 119ms/epoch - 3ms/step\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0926 - accuracy: 0.9626 - f1_m: 0.7109 - precision_m: 0.5516 - recall_m: 1.0000 - 126ms/epoch - 3ms/step\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0930 - accuracy: 0.9622 - f1_m: 0.7107 - precision_m: 0.5513 - recall_m: 1.0000 - 136ms/epoch - 3ms/step\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0927 - accuracy: 0.9622 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 125ms/epoch - 3ms/step\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0924 - accuracy: 0.9625 - f1_m: 0.7104 - precision_m: 0.5509 - recall_m: 1.0000 - 189ms/epoch - 4ms/step\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0927 - accuracy: 0.9619 - f1_m: 0.7103 - precision_m: 0.5508 - recall_m: 1.0000 - 210ms/epoch - 5ms/step\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0922 - accuracy: 0.9627 - f1_m: 0.7105 - precision_m: 0.5510 - recall_m: 1.0000 - 209ms/epoch - 5ms/step\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0922 - accuracy: 0.9628 - f1_m: 0.7096 - precision_m: 0.5500 - recall_m: 1.0000 - 198ms/epoch - 5ms/step\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0918 - accuracy: 0.9624 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 198ms/epoch - 5ms/step\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0920 - accuracy: 0.9627 - f1_m: 0.7097 - precision_m: 0.5501 - recall_m: 1.0000 - 188ms/epoch - 4ms/step\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0922 - accuracy: 0.9622 - f1_m: 0.7101 - precision_m: 0.5506 - recall_m: 1.0000 - 191ms/epoch - 5ms/step\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0918 - accuracy: 0.9627 - f1_m: 0.7099 - precision_m: 0.5504 - recall_m: 1.0000 - 140ms/epoch - 3ms/step\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0918 - accuracy: 0.9630 - f1_m: 0.7106 - precision_m: 0.5512 - recall_m: 1.0000 - 137ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2540473b190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the feed forward neural network model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=53, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(20, activation='softmax')) #for multiclass classification\n",
    "    #Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy',f1_m,precision_m, recall_m]\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "#institate the model\n",
    "model = build_model()\n",
    "\n",
    "#fit the model\n",
    "#start = time.time()\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=2000,verbose=2)\n",
    "#end_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2573/2573 [==============================] - 4s 1ms/step - loss: 0.0916 - accuracy: 0.9626 - f1_m: 0.5507 - precision_m: 0.5506 - recall_m: 0.5511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09162107110023499,\n",
       " 0.9626269340515137,\n",
       " 0.5507278442382812,\n",
       " 0.5505732893943787,\n",
       " 0.55110764503479]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_confusion_matrix\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332\n",
      "Epoch 1/200\n",
      "42/42 - 4s - loss: 2.1981 - accuracy: 0.6017 - 4s/epoch - 89ms/step\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 1.6992 - accuracy: 0.7320 - 329ms/epoch - 8ms/step\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.8954 - accuracy: 0.7333 - 342ms/epoch - 8ms/step\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.5858 - accuracy: 0.7517 - 317ms/epoch - 8ms/step\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.4845 - accuracy: 0.7806 - 313ms/epoch - 7ms/step\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.4076 - accuracy: 0.8301 - 324ms/epoch - 8ms/step\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.3388 - accuracy: 0.8676 - 325ms/epoch - 8ms/step\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.2883 - accuracy: 0.8756 - 333ms/epoch - 8ms/step\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.2567 - accuracy: 0.8859 - 310ms/epoch - 7ms/step\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.2366 - accuracy: 0.8953 - 302ms/epoch - 7ms/step\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.2218 - accuracy: 0.9012 - 277ms/epoch - 7ms/step\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.2093 - accuracy: 0.9082 - 295ms/epoch - 7ms/step\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.1980 - accuracy: 0.9140 - 336ms/epoch - 8ms/step\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.1873 - accuracy: 0.9203 - 263ms/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.1774 - accuracy: 0.9275 - 302ms/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.1683 - accuracy: 0.9320 - 251ms/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.1598 - accuracy: 0.9383 - 272ms/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.1529 - accuracy: 0.9426 - 250ms/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.1473 - accuracy: 0.9450 - 282ms/epoch - 7ms/step\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.1426 - accuracy: 0.9469 - 249ms/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.1390 - accuracy: 0.9486 - 243ms/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.1359 - accuracy: 0.9502 - 247ms/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.1330 - accuracy: 0.9516 - 251ms/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.1309 - accuracy: 0.9522 - 249ms/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.1288 - accuracy: 0.9531 - 319ms/epoch - 8ms/step\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.1269 - accuracy: 0.9542 - 306ms/epoch - 7ms/step\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.1254 - accuracy: 0.9546 - 262ms/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.1240 - accuracy: 0.9551 - 313ms/epoch - 7ms/step\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.1226 - accuracy: 0.9553 - 268ms/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.1227 - accuracy: 0.9547 - 279ms/epoch - 7ms/step\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.1206 - accuracy: 0.9559 - 286ms/epoch - 7ms/step\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.1197 - accuracy: 0.9558 - 255ms/epoch - 6ms/step\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.1188 - accuracy: 0.9563 - 252ms/epoch - 6ms/step\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.1180 - accuracy: 0.9559 - 255ms/epoch - 6ms/step\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.1174 - accuracy: 0.9561 - 277ms/epoch - 7ms/step\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.1165 - accuracy: 0.9570 - 284ms/epoch - 7ms/step\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.1163 - accuracy: 0.9566 - 270ms/epoch - 6ms/step\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.1151 - accuracy: 0.9570 - 299ms/epoch - 7ms/step\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.1145 - accuracy: 0.9573 - 419ms/epoch - 10ms/step\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.1139 - accuracy: 0.9573 - 490ms/epoch - 12ms/step\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.1133 - accuracy: 0.9571 - 345ms/epoch - 8ms/step\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.1128 - accuracy: 0.9577 - 284ms/epoch - 7ms/step\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.1123 - accuracy: 0.9578 - 340ms/epoch - 8ms/step\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.1114 - accuracy: 0.9579 - 278ms/epoch - 7ms/step\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.1113 - accuracy: 0.9579 - 262ms/epoch - 6ms/step\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.1105 - accuracy: 0.9581 - 307ms/epoch - 7ms/step\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.1097 - accuracy: 0.9581 - 298ms/epoch - 7ms/step\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.1091 - accuracy: 0.9580 - 348ms/epoch - 8ms/step\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.1086 - accuracy: 0.9584 - 296ms/epoch - 7ms/step\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.1080 - accuracy: 0.9583 - 258ms/epoch - 6ms/step\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.1071 - accuracy: 0.9581 - 252ms/epoch - 6ms/step\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.1066 - accuracy: 0.9586 - 247ms/epoch - 6ms/step\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.1065 - accuracy: 0.9584 - 287ms/epoch - 7ms/step\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.1055 - accuracy: 0.9588 - 300ms/epoch - 7ms/step\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.1049 - accuracy: 0.9588 - 361ms/epoch - 9ms/step\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.1044 - accuracy: 0.9588 - 394ms/epoch - 9ms/step\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.1038 - accuracy: 0.9590 - 409ms/epoch - 10ms/step\n",
      "Epoch 58/200\n",
      "42/42 - 1s - loss: 0.1035 - accuracy: 0.9591 - 518ms/epoch - 12ms/step\n",
      "Epoch 59/200\n",
      "42/42 - 1s - loss: 0.1030 - accuracy: 0.9593 - 500ms/epoch - 12ms/step\n",
      "Epoch 60/200\n",
      "42/42 - 1s - loss: 0.1026 - accuracy: 0.9593 - 583ms/epoch - 14ms/step\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.1023 - accuracy: 0.9596 - 404ms/epoch - 10ms/step\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.1025 - accuracy: 0.9584 - 348ms/epoch - 8ms/step\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.1020 - accuracy: 0.9590 - 317ms/epoch - 8ms/step\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.1017 - accuracy: 0.9592 - 281ms/epoch - 7ms/step\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.1012 - accuracy: 0.9599 - 250ms/epoch - 6ms/step\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.1011 - accuracy: 0.9593 - 261ms/epoch - 6ms/step\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.1010 - accuracy: 0.9598 - 276ms/epoch - 7ms/step\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.1006 - accuracy: 0.9596 - 290ms/epoch - 7ms/step\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.1001 - accuracy: 0.9601 - 273ms/epoch - 7ms/step\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.0999 - accuracy: 0.9604 - 266ms/epoch - 6ms/step\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.0998 - accuracy: 0.9600 - 257ms/epoch - 6ms/step\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.0993 - accuracy: 0.9602 - 256ms/epoch - 6ms/step\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.0990 - accuracy: 0.9606 - 265ms/epoch - 6ms/step\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.0988 - accuracy: 0.9605 - 267ms/epoch - 6ms/step\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.0989 - accuracy: 0.9605 - 253ms/epoch - 6ms/step\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.0982 - accuracy: 0.9608 - 259ms/epoch - 6ms/step\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.0986 - accuracy: 0.9605 - 259ms/epoch - 6ms/step\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.0982 - accuracy: 0.9612 - 256ms/epoch - 6ms/step\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.0979 - accuracy: 0.9607 - 257ms/epoch - 6ms/step\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.0980 - accuracy: 0.9606 - 258ms/epoch - 6ms/step\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.0973 - accuracy: 0.9613 - 266ms/epoch - 6ms/step\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9612 - 287ms/epoch - 7ms/step\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9616 - 269ms/epoch - 6ms/step\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.0968 - accuracy: 0.9616 - 289ms/epoch - 7ms/step\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.0971 - accuracy: 0.9608 - 291ms/epoch - 7ms/step\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.0965 - accuracy: 0.9614 - 287ms/epoch - 7ms/step\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.0963 - accuracy: 0.9615 - 288ms/epoch - 7ms/step\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.0963 - accuracy: 0.9614 - 289ms/epoch - 7ms/step\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.0962 - accuracy: 0.9614 - 278ms/epoch - 7ms/step\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.0963 - accuracy: 0.9612 - 277ms/epoch - 7ms/step\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.0955 - accuracy: 0.9619 - 277ms/epoch - 7ms/step\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.0952 - accuracy: 0.9620 - 269ms/epoch - 6ms/step\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.0951 - accuracy: 0.9623 - 270ms/epoch - 6ms/step\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.0952 - accuracy: 0.9618 - 270ms/epoch - 6ms/step\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0954 - accuracy: 0.9615 - 271ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0951 - accuracy: 0.9618 - 278ms/epoch - 7ms/step\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0945 - accuracy: 0.9619 - 288ms/epoch - 7ms/step\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0941 - accuracy: 0.9623 - 280ms/epoch - 7ms/step\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0943 - accuracy: 0.9621 - 276ms/epoch - 7ms/step\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.0940 - accuracy: 0.9622 - 253ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0941 - accuracy: 0.9620 - 253ms/epoch - 6ms/step\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0947 - accuracy: 0.9616 - 248ms/epoch - 6ms/step\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0940 - accuracy: 0.9622 - 255ms/epoch - 6ms/step\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0943 - accuracy: 0.9624 - 257ms/epoch - 6ms/step\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0935 - accuracy: 0.9618 - 258ms/epoch - 6ms/step\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0934 - accuracy: 0.9627 - 255ms/epoch - 6ms/step\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0932 - accuracy: 0.9624 - 254ms/epoch - 6ms/step\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0939 - accuracy: 0.9618 - 266ms/epoch - 6ms/step\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0931 - accuracy: 0.9624 - 275ms/epoch - 7ms/step\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0929 - accuracy: 0.9627 - 287ms/epoch - 7ms/step\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0932 - accuracy: 0.9623 - 291ms/epoch - 7ms/step\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0929 - accuracy: 0.9626 - 280ms/epoch - 7ms/step\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0930 - accuracy: 0.9625 - 284ms/epoch - 7ms/step\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0928 - accuracy: 0.9625 - 286ms/epoch - 7ms/step\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0923 - accuracy: 0.9628 - 283ms/epoch - 7ms/step\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0919 - accuracy: 0.9630 - 283ms/epoch - 7ms/step\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0919 - accuracy: 0.9632 - 287ms/epoch - 7ms/step\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0921 - accuracy: 0.9627 - 277ms/epoch - 7ms/step\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0924 - accuracy: 0.9628 - 271ms/epoch - 6ms/step\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0919 - accuracy: 0.9631 - 281ms/epoch - 7ms/step\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0917 - accuracy: 0.9632 - 285ms/epoch - 7ms/step\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0913 - accuracy: 0.9632 - 266ms/epoch - 6ms/step\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0913 - accuracy: 0.9627 - 263ms/epoch - 6ms/step\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0909 - accuracy: 0.9630 - 273ms/epoch - 6ms/step\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0911 - accuracy: 0.9631 - 277ms/epoch - 7ms/step\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0912 - accuracy: 0.9632 - 283ms/epoch - 7ms/step\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0907 - accuracy: 0.9632 - 275ms/epoch - 7ms/step\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0908 - accuracy: 0.9630 - 289ms/epoch - 7ms/step\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0906 - accuracy: 0.9631 - 271ms/epoch - 6ms/step\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0907 - accuracy: 0.9631 - 272ms/epoch - 6ms/step\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0907 - accuracy: 0.9635 - 269ms/epoch - 6ms/step\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0907 - accuracy: 0.9630 - 278ms/epoch - 7ms/step\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0902 - accuracy: 0.9636 - 275ms/epoch - 7ms/step\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0904 - accuracy: 0.9633 - 275ms/epoch - 7ms/step\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0901 - accuracy: 0.9635 - 294ms/epoch - 7ms/step\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0897 - accuracy: 0.9641 - 293ms/epoch - 7ms/step\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0901 - accuracy: 0.9634 - 310ms/epoch - 7ms/step\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0901 - accuracy: 0.9634 - 275ms/epoch - 7ms/step\n",
      "Epoch 139/200\n",
      "42/42 - 0s - loss: 0.0900 - accuracy: 0.9634 - 272ms/epoch - 6ms/step\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0900 - accuracy: 0.9637 - 273ms/epoch - 7ms/step\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0892 - accuracy: 0.9638 - 275ms/epoch - 7ms/step\n",
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0896 - accuracy: 0.9632 - 258ms/epoch - 6ms/step\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0902 - accuracy: 0.9634 - 257ms/epoch - 6ms/step\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0903 - accuracy: 0.9630 - 259ms/epoch - 6ms/step\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0891 - accuracy: 0.9640 - 249ms/epoch - 6ms/step\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0889 - accuracy: 0.9641 - 252ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0893 - accuracy: 0.9638 - 269ms/epoch - 6ms/step\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0886 - accuracy: 0.9641 - 262ms/epoch - 6ms/step\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0885 - accuracy: 0.9642 - 252ms/epoch - 6ms/step\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0883 - accuracy: 0.9639 - 253ms/epoch - 6ms/step\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0883 - accuracy: 0.9642 - 253ms/epoch - 6ms/step\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0888 - accuracy: 0.9640 - 254ms/epoch - 6ms/step\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0887 - accuracy: 0.9639 - 259ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0880 - accuracy: 0.9643 - 260ms/epoch - 6ms/step\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0879 - accuracy: 0.9642 - 273ms/epoch - 6ms/step\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0878 - accuracy: 0.9644 - 261ms/epoch - 6ms/step\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0883 - accuracy: 0.9642 - 260ms/epoch - 6ms/step\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0873 - accuracy: 0.9646 - 255ms/epoch - 6ms/step\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0876 - accuracy: 0.9646 - 251ms/epoch - 6ms/step\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0881 - accuracy: 0.9644 - 251ms/epoch - 6ms/step\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0877 - accuracy: 0.9643 - 272ms/epoch - 6ms/step\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0880 - accuracy: 0.9643 - 288ms/epoch - 7ms/step\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0884 - accuracy: 0.9640 - 320ms/epoch - 8ms/step\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0870 - accuracy: 0.9647 - 345ms/epoch - 8ms/step\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0870 - accuracy: 0.9643 - 253ms/epoch - 6ms/step\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0871 - accuracy: 0.9647 - 250ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0869 - accuracy: 0.9648 - 277ms/epoch - 7ms/step\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0868 - accuracy: 0.9648 - 306ms/epoch - 7ms/step\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0870 - accuracy: 0.9646 - 288ms/epoch - 7ms/step\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0865 - accuracy: 0.9651 - 287ms/epoch - 7ms/step\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0868 - accuracy: 0.9646 - 279ms/epoch - 7ms/step\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0862 - accuracy: 0.9650 - 448ms/epoch - 11ms/step\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0860 - accuracy: 0.9654 - 287ms/epoch - 7ms/step\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0869 - accuracy: 0.9646 - 449ms/epoch - 11ms/step\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0862 - accuracy: 0.9649 - 306ms/epoch - 7ms/step\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0859 - accuracy: 0.9652 - 288ms/epoch - 7ms/step\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0860 - accuracy: 0.9648 - 316ms/epoch - 8ms/step\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0857 - accuracy: 0.9652 - 301ms/epoch - 7ms/step\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0858 - accuracy: 0.9647 - 327ms/epoch - 8ms/step\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0860 - accuracy: 0.9650 - 286ms/epoch - 7ms/step\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0855 - accuracy: 0.9651 - 291ms/epoch - 7ms/step\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0855 - accuracy: 0.9650 - 309ms/epoch - 7ms/step\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0864 - accuracy: 0.9644 - 296ms/epoch - 7ms/step\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0854 - accuracy: 0.9648 - 290ms/epoch - 7ms/step\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0852 - accuracy: 0.9648 - 282ms/epoch - 7ms/step\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0850 - accuracy: 0.9655 - 281ms/epoch - 7ms/step\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0847 - accuracy: 0.9654 - 281ms/epoch - 7ms/step\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0852 - accuracy: 0.9650 - 282ms/epoch - 7ms/step\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0850 - accuracy: 0.9653 - 296ms/epoch - 7ms/step\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0847 - accuracy: 0.9652 - 289ms/epoch - 7ms/step\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0848 - accuracy: 0.9653 - 287ms/epoch - 7ms/step\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0847 - accuracy: 0.9653 - 285ms/epoch - 7ms/step\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0846 - accuracy: 0.9652 - 287ms/epoch - 7ms/step\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0845 - accuracy: 0.9653 - 289ms/epoch - 7ms/step\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0845 - accuracy: 0.9655 - 300ms/epoch - 7ms/step\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0846 - accuracy: 0.9654 - 297ms/epoch - 7ms/step\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0843 - accuracy: 0.9654 - 296ms/epoch - 7ms/step\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0842 - accuracy: 0.9657 - 294ms/epoch - 7ms/step\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0845 - accuracy: 0.9655 - 268ms/epoch - 6ms/step\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0842 - accuracy: 0.9655 - 265ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x254023e3af0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, return_sequences=True,input_shape=(1,53)))\n",
    "    model.add(LSTM(20, return_sequences=True))\n",
    "    model.add(Dense(10, activation='softmax')) #for multiclass classification\n",
    "    #Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "                  # metrics=['accuracy',f1_m,precision_m, recall_m]\n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "#The LSTM input layer must be 3D.\n",
    "#The meaning of the 3 input dimensions are: samples, time steps, and features.\n",
    "#reshape input data\n",
    "x_train_array = array(x_train) #array has been declared in the previous cell\n",
    "print(len(x_train_array))\n",
    "x_train_reshaped = x_train_array.reshape(x_train_array.shape[0],1,53)\n",
    "\n",
    "#reshape output data\n",
    "x_test_array=  array(x_test)\n",
    "x_test_reshaped = x_test_array.reshape(x_test_array.shape[0],1,53) \n",
    "\n",
    "\n",
    "#institate the model\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "#fit the model\n",
    "#start = time.time()\n",
    "model.fit(x_train_reshaped, y_train, epochs=200, batch_size=2000,verbose=2)\n",
    "#end_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 1, 53), found shape=(None, 53)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(x_test, y_test)\n\u001b[0;32m      2\u001b[0m results\n",
      "File \u001b[1;32mc:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filensjf0c0o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\i2u3e\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 1, 53), found shape=(None, 53)\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c744276e8e5978d051ca61c4c94574577cb267dc67a8c26bdf2197a085adc3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
