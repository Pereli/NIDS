{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_train_test():\n",
    "    root = '../input/unsw-nb15/'\n",
    "    train = pd.read_csv(root+'UNSW_NB15_training-set.csv')\n",
    "    test = pd.read_csv(root+'UNSW_NB15_testing-set.csv')\n",
    "    \n",
    "    if train.shape[0] == 82332:\n",
    "        print(\"Train and test sets are reversed here. Fixing them.\")\n",
    "        train, test = test, train\n",
    "    drop_columns = ['attack_cat', 'id']\n",
    "    for df in [train, test]:\n",
    "        for col in drop_columns:\n",
    "            if col in df.columns:\n",
    "                print('Dropping '+col)\n",
    "                df.drop([col], axis=1, inplace=True)\n",
    "    return train, test\n",
    "\n",
    "def get_cat_columns(train):\n",
    "    categorical = []\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == 'object':\n",
    "            categorical.append(col)\n",
    "    return categorical\n",
    "    \n",
    "def label_encode(train, test):\n",
    "    for col in get_cat_columns(train):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))\n",
    "    return train, test\n",
    "\n",
    "def feature_engineer(df):\n",
    "    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n",
    "    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n",
    "    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n",
    "    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n",
    "    return df\n",
    "\n",
    "def get_train_test(train, test, label_encoding=False, scaler=None):\n",
    "    x_train, y_train = train.drop(['label'], axis=1), train['label']\n",
    "    x_test, y_test = test.drop(['label'], axis=1), test['label']\n",
    "    \n",
    "    x_train, x_test = feature_engineer(x_train), feature_engineer(x_test)\n",
    "    \n",
    "    categorical_columns = get_cat_columns(x_train)\n",
    "    non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]\n",
    "    if scaler is not None:\n",
    "        x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n",
    "        x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n",
    "\n",
    "    if label_encoding:\n",
    "        x_train, x_test = label_encode(x_train, x_test)\n",
    "        features = x_train.columns\n",
    "    else:\n",
    "        x_train = pd.get_dummies(x_train)\n",
    "        x_test = pd.get_dummies(x_test)\n",
    "        print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n",
    "        features = list(set(x_train.columns) & set(x_test.columns))\n",
    "    print(f\"Number of features {len(features)}\")\n",
    "    x_train = x_train[features]\n",
    "    x_test = x_test[features]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def show_feature_importance(importance, columns):\n",
    "    feature_importance = pd.DataFrame(zip(columns, importance), columns=['Feature', 'Importance'])\n",
    "    feature_importance['Importance'] /= feature_importance['Importance'].sum()*0.01\n",
    "    return feature_importance.sort_values(by=\"Importance\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
