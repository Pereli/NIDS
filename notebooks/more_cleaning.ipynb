{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test sets are reversed. Fixing. \n",
      "Dropping attack_cat\n",
      "Dropping id\n",
      "Dropping response_body_len\n",
      "Dropping is_sm_ips_ports\n",
      "Dropping ct_flw_http_mthd\n",
      "Dropping trans_depth\n",
      "Dropping dwin\n",
      "Dropping ct_ftp_cmd\n",
      "Dropping is_ftp_login\n",
      "Dropping attack_cat\n",
      "Dropping id\n",
      "Dropping response_body_len\n",
      "Dropping is_sm_ips_ports\n",
      "Dropping ct_flw_http_mthd\n",
      "Dropping trans_depth\n",
      "Dropping dwin\n",
      "Dropping ct_ftp_cmd\n",
      "Dropping is_ftp_login\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/UNSW_NB15_training-set.csv')\n",
    "test = pd.read_csv('../data/UNSW_NB15_training-set.csv')\n",
    "if train.shape[0]<100000:\n",
    "    print(\"Train test sets are reversed. Fixing. \")\n",
    "    train, test = test, train\n",
    "\n",
    "drop_columns = ['attack_cat', 'id'] + ['response_body_len', 'is_sm_ips_ports', 'ct_flw_http_mthd', 'trans_depth', 'dwin', 'ct_ftp_cmd', 'is_ftp_login']\n",
    "for df in [train, test]:\n",
    "    for col in drop_columns:\n",
    "        if col in df.columns:\n",
    "            print('Dropping '+col)\n",
    "            df.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feature_engineer(df):\n",
    "    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n",
    "    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n",
    "    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n",
    "    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n",
    "    return df\n",
    "\n",
    "def get_cat_columns(train):\n",
    "    categorical = []\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == 'object':\n",
    "            categorical.append(col)\n",
    "    return categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column mismatch set(), set()\n",
      "Number of features 53\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train.drop(['label'], axis=1), train['label']\n",
    "x_test, y_test = test.drop(['label'], axis=1), test['label']\n",
    "\n",
    "x_train, x_test = feature_engineer(x_train), feature_engineer(x_test)\n",
    "\n",
    "categorical_columns = get_cat_columns(x_train)\n",
    "non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n",
    "x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n",
    "\n",
    "\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n",
    "features = list(set(x_train.columns) & set(x_test.columns))\n",
    "\n",
    "print(f\"Number of features {len(features)}\")\n",
    "x_train = x_train[features]\n",
    "x_test = x_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train['label'] = y_train\n",
    "x_test['label'] = y_test\n",
    "x_train.to_csv('../data/train.csv', index=False)\n",
    "x_test.to_csv('../data/test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe6a85375423fab5ed3ee0804ced7d5909b467d08d2a448d237bbd9b686727d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
